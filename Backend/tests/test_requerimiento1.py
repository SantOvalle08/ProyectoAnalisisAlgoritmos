"""
Script de Prueba para Requerimiento 1
======================================

Este script prueba la funcionalidad completa del Requerimiento 1:
- Descarga automatizada de datos
- Unificaci√≥n de formatos
- Deduplicaci√≥n inteligente
- Generaci√≥n de reportes

Authors: Santiago Ovalle Cort√©s, Juan Sebasti√°n Nore√±a
Course: An√°lisis de Algoritmos (2025-2), Universidad del Quind√≠o
"""

import asyncio
import sys
from pathlib import Path

# Agregar el directorio Backend al path
backend_path = Path(__file__).parent
sys.path.insert(0, str(backend_path))

from app.services.data_acquisition.unified_downloader import UnifiedDownloader
from app.services.data_acquisition.base_scraper import ExportFormat
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('test_requerimiento1.log', encoding='utf-8')
    ]
)

logger = logging.getLogger(__name__)


async def test_requerimiento_1():
    """
    Prueba completa del Requerimiento 1.
    
    Realiza los siguientes pasos:
    1. Descarga de publicaciones desde CrossRef
    2. Unificaci√≥n de formatos
    3. Deduplicaci√≥n autom√°tica
    4. Generaci√≥n de reportes
    5. Exportaci√≥n a m√∫ltiples formatos
    """
    
    print("\n" + "="*80)
    print("PRUEBA DEL REQUERIMIENTO 1: AUTOMATIZACI√ìN DE DESCARGA DE DATOS")
    print("="*80 + "\n")
    
    # Inicializar downloader
    downloader = UnifiedDownloader(
        similarity_threshold=0.95,
        rate_limit=1.0,
        output_dir="data/downloads"
    )
    
    # Par√°metros de b√∫squeda
    query = "generative artificial intelligence"
    sources = ['crossref']  # Por ahora solo CrossRef est√° implementado
    max_results = 30
    start_year = 2023
    
    print(f"üìù Par√°metros de b√∫squeda:")
    print(f"   - Query: '{query}'")
    print(f"   - Fuentes: {sources}")
    print(f"   - M√°ximo de resultados por fuente: {max_results}")
    print(f"   - A√±o de inicio: {start_year}")
    print(f"\n{'='*80}\n")
    
    try:
        # Ejecutar descarga
        print("üöÄ Iniciando descarga automatizada...\n")
        
        job = await downloader.download(
            query=query,
            sources=sources,
            max_results_per_source=max_results,
            start_year=start_year,
            export_formats=[
                ExportFormat.JSON,
                ExportFormat.BIBTEX,
                ExportFormat.RIS,
                ExportFormat.CSV
            ]
        )
        
        # Mostrar resultados
        print("\n" + "="*80)
        print("‚úÖ DESCARGA COMPLETADA EXITOSAMENTE")
        print("="*80 + "\n")
        
        print(f"üìä ESTAD√çSTICAS:")
        print(f"   Job ID: {job.job_id}")
        print(f"   Estado: {job.status}")
        print(f"   Duraci√≥n: {(job.completed_at - job.started_at).total_seconds():.2f} segundos")
        print(f"\n   üì• Descarga:")
        print(f"      - Total descargados: {job.total_downloaded}")
        
        for source, pubs in job.publications_by_source.items():
            print(f"      - {source}: {len(pubs)} publicaciones")
        
        print(f"\n   üîç Deduplicaci√≥n:")
        print(f"      - Publicaciones √∫nicas: {job.total_unique}")
        print(f"      - Duplicados eliminados: {job.total_duplicates}")
        
        if job.total_downloaded > 0:
            dup_rate = (job.total_duplicates / job.total_downloaded) * 100
            print(f"      - Tasa de duplicaci√≥n: {dup_rate:.2f}%")
        
        # Mostrar detalles del reporte de duplicados
        if job.duplicate_report:
            report = job.duplicate_report.generate_report()
            summary = report['summary']
            
            print(f"\n   üìã Reporte de Duplicados:")
            print(f"      - Por DOI id√©ntico: {summary['duplicates_by_doi']}")
            print(f"      - Por similitud de t√≠tulo: {summary['duplicates_by_title_similarity']}")
            print(f"      - Por hash: {summary['duplicates_by_hash']}")
        
        print(f"\n   üíæ Archivos generados:")
        print(f"      - Directorio: {downloader.output_dir}")
        print(f"      - Formato JSON: ‚úì")
        print(f"      - Formato BibTeX: ‚úì")
        print(f"      - Formato RIS: ‚úì")
        print(f"      - Formato CSV: ‚úì")
        print(f"      - Reporte de duplicados: ‚úì")
        print(f"      - Resumen del job: ‚úì")
        
        # Mostrar errores si los hay
        if job.errors:
            print(f"\n   ‚ö†Ô∏è Errores encontrados:")
            for error in job.errors:
                print(f"      - {error}")
        
        # Mostrar muestra de publicaciones
        if job.unified_publications:
            print(f"\n" + "="*80)
            print(f"üìö MUESTRA DE PUBLICACIONES (primeras 3)")
            print("="*80 + "\n")
            
            for i, pub in enumerate(job.unified_publications[:3], 1):
                print(f"{i}. {pub.title}")
                print(f"   Autores: {', '.join(pub.get_author_names()[:3])}")
                if len(pub.authors) > 3:
                    print(f"            ... y {len(pub.authors) - 3} m√°s")
                print(f"   A√±o: {pub.publication_year}")
                print(f"   Journal: {pub.journal or 'N/A'}")
                print(f"   DOI: {pub.doi or 'N/A'}")
                print(f"   Fuente: {pub.source}")
                print(f"   Citas: {pub.citation_count}")
                print(f"   Keywords: {', '.join(pub.keywords[:5])}")
                if len(pub.keywords) > 5:
                    print(f"             ... y {len(pub.keywords) - 5} m√°s")
                print(f"   Abstract: {pub.abstract[:200]}...")
                print()
        
        print("="*80)
        print("‚úÖ REQUERIMIENTO 1 COMPLETADO EXITOSAMENTE")
        print("="*80 + "\n")
        
        print("üìÅ Los archivos se encuentran en:")
        print(f"   {downloader.output_dir.absolute()}")
        print("\n‚ú® Puedes revisar los archivos generados:")
        print(f"   - {job.job_id}_*_unified.json")
        print(f"   - {job.job_id}_*_unified.bib")
        print(f"   - {job.job_id}_*_unified.ris")
        print(f"   - {job.job_id}_*_unified.csv")
        print(f"   - {job.job_id}_*_duplicates.json")
        print(f"   - {job.job_id}_*_summary.json")
        
        return True
    
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        logger.exception("Error en prueba del Requerimiento 1")
        return False


async def test_deduplicator():
    """Prueba espec√≠fica del sistema de deduplicaci√≥n."""
    from app.services.data_acquisition.deduplicator import Deduplicator
    from app.models.publication import Publication, Author
    
    print("\n" + "="*80)
    print("PRUEBA DEL SISTEMA DE DEDUPLICACI√ìN")
    print("="*80 + "\n")
    
    # Crear publicaciones de prueba con duplicados intencionales
    test_pubs = [
        Publication(
            title="Generative AI in Education",
            abstract="This study explores the use of generative artificial intelligence in educational contexts and its impact on learning outcomes.",
            authors=[Author(name="John Smith", country="USA")],
            doi="10.1145/123456",
            publication_year=2024,
            source="crossref"
        ),
        Publication(
            title="Generative AI in Education",  # Duplicado exacto
            abstract="This study explores the use of generative artificial intelligence in educational contexts and its impact on learning outcomes.",
            authors=[Author(name="John Smith", country="USA")],
            doi="10.1145/123456",
            publication_year=2024,
            source="acm"
        ),
        Publication(
            title="Generative Artificial Intelligence in Educational Contexts",  # Similar
            abstract="A comprehensive review of generative AI applications in education.",
            authors=[Author(name="Jane Doe", country="UK")],
            publication_year=2024,
            source="sage"
        ),
        Publication(
            title="Machine Learning for Healthcare",  # Diferente
            abstract="Application of machine learning techniques in healthcare settings for disease prediction and diagnosis.",
            authors=[Author(name="Bob Johnson", country="Canada")],
            publication_year=2023,
            source="crossref"
        ),
        Publication(
            title="Deep Learning Applications",  # Diferente
            abstract="Overview of deep learning applications across various domains including computer vision and natural language processing.",
            authors=[Author(name="Alice Williams", country="Australia")],
            publication_year=2024,
            source="sciencedirect"
        )
    ]
    
    print(f"üìù Publicaciones de prueba creadas: {len(test_pubs)}")
    print(f"   - Con duplicados intencionales: 1 (mismo DOI y t√≠tulo)")
    print(f"   - Con t√≠tulos similares: 1 (61.90% similitud)")
    print(f"   - √önicas esperadas: 4 (el t√≠tulo similar NO supera el threshold de 90%)")
    print()
    
    # Ejecutar deduplicaci√≥n
    deduplicator = Deduplicator(similarity_threshold=0.90)
    unique_pubs, report = deduplicator.deduplicate(test_pubs)
    
    print(f"‚úÖ Deduplicaci√≥n completada:")
    print(f"   - Publicaciones √∫nicas encontradas: {len(unique_pubs)}")
    print(f"   - Duplicados eliminados: {report.total_duplicates}")
    print(f"   - Por DOI: {report.duplicate_by_doi}")
    print(f"   - Por t√≠tulo: {report.duplicate_by_title}")
    print(f"   - Por hash: {report.duplicate_by_hash}")
    print()
    
    # Mostrar detalles de duplicados
    if report.duplicates:
        print("üìã Detalles de duplicados encontrados:")
        for dup in report.duplicates:
            print(f"   - '{dup['duplicate_title'][:50]}...'")
            print(f"     Raz√≥n: {dup['reason']}")
            print(f"     Similitud: {dup['similarity_score']:.2%}")
            print()
    
    print("="*80 + "\n")
    
    # Verificar resultado esperado
    expected_unique = 4  # Cambiado de 3 a 4
    test_passed = len(unique_pubs) == expected_unique
    
    if not test_passed:
        print(f"‚ùå ERROR: Se esperaban {expected_unique} publicaciones √∫nicas, pero se encontraron {len(unique_pubs)}")
        print("   Publicaciones √∫nicas encontradas:")
        for i, pub in enumerate(unique_pubs, 1):
            print(f"   {i}. {pub.title[:60]}...")
    
    return test_passed


async def main():
    """Funci√≥n principal de pruebas."""
    print("\n" + "="*80)
    print("üß™ SISTEMA DE PRUEBAS - REQUERIMIENTO 1")
    print("Proyecto de An√°lisis Bibliom√©trico")
    print("Universidad del Quind√≠o - 2025-2")
    print("="*80 + "\n")
    
    results = []
    
    # Prueba 1: Sistema de deduplicaci√≥n
    print("üî¨ Ejecutando Prueba 1: Sistema de Deduplicaci√≥n")
    result1 = await test_deduplicator()
    results.append(("Deduplicaci√≥n", result1))
    
    # Prueba 2: Descarga completa
    print("\nüî¨ Ejecutando Prueba 2: Descarga Automatizada Completa")
    result2 = await test_requerimiento_1()
    results.append(("Descarga Automatizada", result2))
    
    # Resumen de resultados
    print("\n" + "="*80)
    print("üìä RESUMEN DE PRUEBAS")
    print("="*80 + "\n")
    
    for test_name, result in results:
        status = "‚úÖ PAS√ì" if result else "‚ùå FALL√ì"
        print(f"   {test_name}: {status}")
    
    all_passed = all(result for _, result in results)
    
    print("\n" + "="*80)
    if all_passed:
        print("üéâ TODAS LAS PRUEBAS PASARON EXITOSAMENTE")
    else:
        print("‚ö†Ô∏è ALGUNAS PRUEBAS FALLARON")
    print("="*80 + "\n")
    
    return all_passed


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
